{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct links to results\n",
    "[TF-MoDISco results](#tfm-results)\n",
    "\n",
    "[Summary of motifs](#motif-summary)\n",
    "\n",
    "[TOMTOM matches to motifs](#tomtom)\n",
    "\n",
    "[Sample of seqlets for each motif](#seqlets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from util import import_shap_scores, import_tfmodisco_results, import_peak_table, import_profiles\n",
    "from util import pfm_to_pwm, trim_motif_by_ic\n",
    "from util import figure_to_vdom_image\n",
    "from tomtom import match_motifs_to_database\n",
    "import viz_sequence\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import sklearn.cluster\n",
    "import scipy.cluster.hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "import re\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "preds_path= os.environ[\"TFM_PRED_PATH\"]\n",
    "shap_scores_path = os.environ[\"TFM_SHAP_PATH\"]\n",
    "tfm_results_path = os.environ[\"TFM_TFM_PATH\"]\n",
    "peak_bed_paths = [os.environ[\"TFM_PEAKS_PATH\"]]\n",
    "tomtom_database_path = os.environ[\"TFM_TOMTOM_DB_PATH\"]\n",
    "\n",
    "key = os.environ[\"TFM_KEY\"]\n",
    "number_of_motifs_to_report_export = 5\n",
    "number_of_tomtom_matches_to_report_export = 5\n",
    "motif_file_export_path = os.environ[\"TFM_ANALYSIS_DIR\"]\n",
    "\n",
    "if \"TFM_MOTIF_CACHE\" in os.environ:\n",
    "    tfm_motifs_cache_dir = os.environ[\"TFM_MOTIF_CACHE\"]\n",
    "else:\n",
    "    tfm_motifs_cache_dir = None\n",
    "\n",
    "print(\"Predictions path: %s\" % preds_path)\n",
    "print(\"DeepSHAP scores path: %s\" % shap_scores_path)\n",
    "print(\"TF-MoDISco results path: %s\" % tfm_results_path)\n",
    "print(\"Peaks path: %s\" % peak_bed_paths[0])\n",
    "print(\"TOMTOM database path: %s\" % tomtom_database_path)\n",
    "print(\"Saved TF-MoDISco-derived motifs cache: %s\" % tfm_motifs_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "input_length, profile_length = 2114, 1000\n",
    "shap_score_center_size = 400\n",
    "profile_display_center_size = 400\n",
    "hyp_score_key = \"hyp_scores\"\n",
    "task_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if tfm_motifs_cache_dir:\n",
    "    os.makedirs(tfm_motifs_cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_profiles_and_coords(\n",
    "    seqlets_arr, one_hot_seqs, hyp_scores, true_profs, pred_profs, pred_coords,\n",
    "    input_length, profile_length, input_center_cut_size, profile_center_cut_size,\n",
    "    task_index=None\n",
    "):\n",
    "    \"\"\"\n",
    "    From the seqlets object of a TF-MoDISco pattern's seqlets and alignments,\n",
    "    extracts the predicted and observed profiles of the model, as well as the\n",
    "    set of coordinates for the seqlets.\n",
    "    Arguments:\n",
    "        `seqlets_arr`: a TF-MoDISco pattern's seqlets object array (N-array)\n",
    "        `one_hot_seqs`: an N x R x 4 array of input sequences, where R is\n",
    "            the cut centered size\n",
    "        `hyp_scores`: an N x R x 4 array of hypothetical importance scores\n",
    "        `true_profs`: an N x T x O x 2 array of true profile counts\n",
    "        `pred_profs`: an N x T x O x 2 array of predicted profile probabilities\n",
    "        `pred_coords`: an N x 3 object array of coordinates for the input sequence\n",
    "            underlying the predictions\n",
    "        `input_length`: length of original input sequences, I\n",
    "        `profile_length`: length of profile predictions, O\n",
    "        `input_center_cut_size`: centered cut size of SHAP scores used\n",
    "        `profile_center_cut_size`: size to cut profiles to when returning them, P\n",
    "        `task_index`: index of task to focus on for profiles; if None, returns\n",
    "            profiles for all tasks\n",
    "    Returns an N x (T or 1) x P x 2 array of true profile counts, an\n",
    "    N x (T or 1) x P x 2 array of predicted profile probabilities, an N x Q x 4\n",
    "    array of one-hot seqlet sequences, an N x Q x 4 array of hypothetical seqlet\n",
    "    importance scores, and an N x 3 object array of seqlet coordinates, where P\n",
    "    is the profile cut size and Q is the seqlet length. Returned profiles are\n",
    "    centered at the same center as the seqlets.\n",
    "    Note that it is important that the seqlet indices match exactly with the indices\n",
    "    out of the N. This should be the exact sequences in the original SHAP scores.\n",
    "    \"\"\"\n",
    "    true_seqlet_profs, pred_seqlet_profs, seqlet_seqs, seqlet_hyps, seqlet_coords = [], [], [], [], []\n",
    "    \n",
    "    def seqlet_coord_to_profile_coord(seqlet_coord):\n",
    "        return seqlet_coord + ((input_length - input_center_cut_size) // 2) - ((input_length - profile_length) // 2)\n",
    "    \n",
    "    def seqlet_coord_to_input_coord(seqlet_coord):\n",
    "        return seqlet_coord + ((input_length - input_center_cut_size) // 2)\n",
    "    \n",
    "    \n",
    "    # For each seqlet, fetch the true/predicted profiles\n",
    "    for seqlet in seqlets_arr:\n",
    "        coord_index = seqlet.coor.example_idx\n",
    "        seqlet_start = seqlet.coor.start\n",
    "        seqlet_end = seqlet.coor.end\n",
    "        seqlet_rc = seqlet.coor.is_revcomp\n",
    "        \n",
    "        # Get indices of profile to cut out\n",
    "        seqlet_center = (seqlet_start + seqlet_end) // 2\n",
    "        prof_center = seqlet_coord_to_profile_coord(seqlet_center)\n",
    "        prof_start = prof_center - (profile_center_cut_size // 2)\n",
    "        prof_end = prof_start + profile_center_cut_size\n",
    "        \n",
    "            \n",
    "        true_prof = true_profs[coord_index, prof_start:prof_end]  # (T or 1) x P x 2\n",
    "        pred_prof = pred_profs[coord_index, prof_start:prof_end]  # (T or 1) x P x 2\n",
    "        \n",
    "        true_seqlet_profs.append(true_prof)\n",
    "        pred_seqlet_profs.append(pred_prof)\n",
    "        \n",
    "        # The one-hot-sequences and hypothetical scores are assumed to already by cut/centered,\n",
    "        # so the indices match the seqlet indices\n",
    "        if seqlet_rc:\n",
    "            seqlet_seqs.append(np.flip(one_hot_seqs[coord_index, seqlet_start:seqlet_end], axis=(0, 1)))\n",
    "            seqlet_hyps.append(np.flip(hyp_scores[coord_index, seqlet_start:seqlet_end], axis=(0, 1)))\n",
    "        else:\n",
    "            seqlet_seqs.append(one_hot_seqs[coord_index, seqlet_start:seqlet_end])\n",
    "            seqlet_hyps.append(hyp_scores[coord_index, seqlet_start:seqlet_end])\n",
    "            \n",
    "        # Get the coordinates of the seqlet based on the input coordinates\n",
    "        inp_start = seqlet_coord_to_input_coord(seqlet_start)\n",
    "        inp_end = seqlet_coord_to_input_coord(seqlet_end)\n",
    "        chrom, start, _ = pred_coords[coord_index]\n",
    "        seqlet_coords.append([chrom, start + inp_start, start + inp_end])\n",
    "    \n",
    "    return np.stack(true_seqlet_profs), np.stack(pred_seqlet_profs), np.stack(seqlet_seqs), np.stack(seqlet_hyps), np.array(seqlet_coords, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import SHAP scores, profile predictions, and TF-MoDISco results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import SHAP coordinates and one-hot sequences\n",
    "hyp_scores, _, one_hot_seqs, shap_coords = import_shap_scores(shap_scores_path, hyp_score_key, center_cut_size=shap_score_center_size, remove_non_acgt=False)\n",
    "# This cuts the sequences/scores off just as how TF-MoDISco saw them, but the coordinates are uncut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_profiles(preds_path):\n",
    "    \"\"\"\n",
    "    Imports the set of profile predictions.\n",
    "    Arguments:\n",
    "        `preds_path`: path to predictions/performance metrics of the model\n",
    "    Returns an M x T x O x 2 array of true profile counts, an M x T x O x 2\n",
    "    array of predicted profile probabilities, and an M x 3 object array of\n",
    "    corresponding coordinates.\n",
    "    \"\"\"\n",
    "    with h5py.File(preds_path, \"r\") as f:\n",
    "        num_seqs, input_length, _ = f[\"predictions\"][\"true_profs\"].shape\n",
    "        batch_size = min(1000, num_seqs)\n",
    "        num_batches = int(np.ceil(num_seqs / batch_size))\n",
    "        \n",
    "        true_profs = np.empty((num_seqs, input_length, 2))\n",
    "        pred_profs = np.empty((num_seqs, input_length, 2))\n",
    "        coords = np.empty((num_seqs, 3), dtype=object)\n",
    "        \n",
    "        for i in tqdm.notebook.trange(num_batches, desc=\"Importing predictions\"):\n",
    "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "            true_profs[batch_slice] = f[\"predictions\"][\"true_profs\"][batch_slice]\n",
    "            pred_profs[batch_slice] = f[\"predictions\"][\"pred_profs\"][batch_slice]\n",
    "            coords[batch_slice, 0] = f[\"coords\"][\"coords_chrom\"][batch_slice].astype(str)\n",
    "            coords[batch_slice, 1] = f[\"coords\"][\"coords_start\"][batch_slice]\n",
    "            coords[batch_slice, 2] = f[\"coords\"][\"coords_end\"][batch_slice]\n",
    "    \n",
    "    return true_profs, pred_profs, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the set of all profiles and their coordinates\n",
    "true_profs, pred_profs, all_pred_coords = import_profiles(preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the set of peaks\n",
    "peak_table = import_peak_table(peak_bed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subset the predicted profiles/coordinates to the task-specific SHAP coordinates/scores\n",
    "shap_coords_table = pd.DataFrame(shap_coords, columns=[\"chrom\", \"start\", \"end\"])\n",
    "pred_coords_table = pd.DataFrame(all_pred_coords, columns=[\"chrom\", \"start\", \"end\"])\n",
    "\n",
    "st = pred_coords_table['start'].copy()\n",
    "end = pred_coords_table['end'].copy()\n",
    "pred_coords_table['start']=((st+end)//2)-(input_length//2)\n",
    "pred_coords_table['end']=((st+end))//2+(input_length//2)\n",
    "\n",
    "subset_inds = shap_coords_table.reset_index().drop_duplicates([\"chrom\", \"start\", \"end\"]).merge(\n",
    "    pred_coords_table.reset_index(), on=[\"chrom\", \"start\", \"end\"]\n",
    ").sort_values(\"index_x\")[\"index_y\"].values\n",
    "\n",
    "true_profs = true_profs[subset_inds]\n",
    "pred_profs = pred_profs[subset_inds]\n",
    "pred_coords = pred_coords_table.iloc[subset_inds,:].reset_index(drop=True).to_numpy()\n",
    "\n",
    "#Make sure the coordinates all match\n",
    "assert np.all(pred_coords == shap_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the TF-MoDISco results object\n",
    "tfm_obj = import_tfmodisco_results(tfm_results_path, hyp_scores, one_hot_seqs, shap_score_center_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tfm-results\"></a>\n",
    "## Plot TF-MoDISco results\n",
    "Plot all motifs by metacluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motif_pfms, motif_hcwms, motif_cwms = [], [], []  # Save the trimmed PFMs, hCWMs, and CWMs\n",
    "motif_pfms_short = []  # PFMs that are even more trimmed (for TOMTOM)\n",
    "num_seqlets = []  # Number of seqlets for each motif\n",
    "motif_seqlets = []  # Save seqlets of each motif\n",
    "if tfm_motifs_cache_dir:\n",
    "    motif_hdf5 = h5py.File(os.path.join(tfm_motifs_cache_dir, \"all_motifs.h5\"), \"w\")\n",
    "metaclusters = tfm_obj.metacluster_idx_to_submetacluster_results\n",
    "num_metaclusters = len(metaclusters.keys())\n",
    "for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "    metacluster = metaclusters[metacluster_key]\n",
    "    display(vdomh.h3(\"Metacluster %d/%d\" % (metacluster_i + 1, num_metaclusters)))\n",
    "    patterns = metacluster.seqlets_to_patterns_result.patterns\n",
    "    if not patterns:\n",
    "        break\n",
    "    motif_pfms.append([])\n",
    "    motif_hcwms.append([])\n",
    "    motif_cwms.append([])\n",
    "    motif_pfms_short.append([])\n",
    "    num_seqlets.append([])\n",
    "    motif_seqlets.append([])\n",
    "    num_patterns = len(patterns)\n",
    "    for pattern_i, pattern in enumerate(patterns):\n",
    "        seqlets = pattern.seqlets\n",
    "        display(vdomh.h4(\"Pattern %d/%d\" % (pattern_i + 1, num_patterns)))\n",
    "        display(vdomh.p(\"%d seqlets\" % len(seqlets)))\n",
    "        \n",
    "        pfm = pattern[\"sequence\"].fwd\n",
    "        hcwm = pattern[\"task0_hypothetical_contribs\"].fwd\n",
    "        cwm = pattern[\"task0_contrib_scores\"].fwd\n",
    "        \n",
    "        pfm_fig = viz_sequence.plot_weights(pfm, subticks_frequency=10, return_fig=True)\n",
    "        hcwm_fig = viz_sequence.plot_weights(hcwm, subticks_frequency=10, return_fig=True)\n",
    "        cwm_fig = viz_sequence.plot_weights(cwm, subticks_frequency=10, return_fig=True)\n",
    "        pfm_fig.tight_layout()\n",
    "        hcwm_fig.tight_layout()\n",
    "        cwm_fig.tight_layout()\n",
    "        \n",
    "        motif_table = vdomh.table(\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"Sequence (PFM)\"),\n",
    "                vdomh.td(figure_to_vdom_image(pfm_fig))\n",
    "            ),\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"Hypothetical contributions (hCWM)\"),\n",
    "                vdomh.td(figure_to_vdom_image(hcwm_fig))\n",
    "            ),\n",
    "            vdomh.tr(\n",
    "                vdomh.td(\"Actual contributions (CWM)\"),\n",
    "                vdomh.td(figure_to_vdom_image(cwm_fig))\n",
    "            )\n",
    "        )\n",
    "        display(motif_table)\n",
    "        plt.close(\"all\")  # Remove all standing figures\n",
    "        \n",
    "        # Trim motif based on information content\n",
    "        short_trimmed_pfm = trim_motif_by_ic(pfm, pfm)\n",
    "        motif_pfms_short[-1].append(short_trimmed_pfm)\n",
    "        \n",
    "        # Expand trimming to +/- 4bp on either side\n",
    "        trimmed_pfm = trim_motif_by_ic(pfm, pfm, pad=4)\n",
    "        trimmed_hcwm = trim_motif_by_ic(pfm, hcwm, pad=4)\n",
    "        trimmed_cwm = trim_motif_by_ic(pfm, cwm, pad=4)\n",
    "        \n",
    "        motif_pfms[-1].append(trimmed_pfm)\n",
    "        motif_hcwms[-1].append(trimmed_hcwm)\n",
    "        motif_cwms[-1].append(trimmed_cwm)\n",
    "        \n",
    "        num_seqlets[-1].append(len(seqlets))\n",
    "        \n",
    "        seqlet_true_profs, seqlet_pred_profs, seqlet_seqs, seqlet_hyps, seqlet_coords = extract_profiles_and_coords(\n",
    "            seqlets, one_hot_seqs, hyp_scores, true_profs, pred_profs, pred_coords,\n",
    "            input_length, profile_length, shap_score_center_size,\n",
    "            profile_display_center_size, task_index=task_index\n",
    "        )\n",
    "        \n",
    "        motif_seqlets[-1].append((seqlet_seqs, seqlet_hyps))\n",
    "\n",
    "        assert np.allclose(np.sum(seqlet_seqs, axis=0) / len(seqlet_seqs), pattern[\"sequence\"].fwd)\n",
    "        # ^Sanity check: PFM derived from seqlets match the PFM stored in the pattern\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tomtom\"></a>\n",
    "## Top TOMTOM matches for each motif\n",
    "\n",
    "Here, the TF-MoDISco motifs are plotted as hCWMs, but the TOMTOM matches are shown as PWMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches_to_keep = 10\n",
    "num_matches_to_show = 5\n",
    "\n",
    "\n",
    "tomtom_matches_lst = []\n",
    "\n",
    "for i in range(len(motif_pfms)):\n",
    "       \n",
    "    # Compute TOMTOM matches for all motifs in the metacluster at once\n",
    "    out_dir = os.path.join(tfm_motifs_cache_dir, \"tomtom\", \"metacluster_%d\" % i) if tfm_motifs_cache_dir else None\n",
    "    tomtom_matches = match_motifs_to_database(motif_pfms_short[i], top_k=num_matches_to_keep, database_path=tomtom_database_path, temp_dir=out_dir)\n",
    "    tomtom_matches_lst.append(tomtom_matches)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_lst = []\n",
    "\n",
    "for i in range(len(motif_cwms[0])):\n",
    "    try:\n",
    "        motif_cwm = motif_cwms[0][i]\n",
    "\n",
    "        max_cwm_base = motif_cwm.argmax(axis=1)\n",
    "        base_below_threshold = motif_cwm.max(axis=1)<0.0025\n",
    "        bases = ['A','C','G','T']\n",
    "        motif = ['N' if base_below_threshold[index] else bases[x] for index, x in enumerate(max_cwm_base)]\n",
    "        motif_str = ''.join(motif)\n",
    "        \n",
    "        tomtom_motif_str = tomtom_matches_lst[0][i][0][0]\n",
    "        tomtom_motif_str = re.sub('_HUMAN.H11MO.*,*', '',tomtom_motif_str)\n",
    "        tomtom_motif_str = re.sub('MA[0-9]*.*_', '',tomtom_motif_str)\n",
    "        \n",
    "        if motif_str=='N'*len(motif_str): #this will hopefully remove all low important repeat motifs\n",
    "            motifs_lst.append(f'NNNN,None,0.0')\n",
    "        else:    \n",
    "            motifs_lst.append(f'{motif_str},{tomtom_motif_str},{motif_cwm.max()}')\n",
    "    \n",
    "    # if things fail create a NNNN:None output\n",
    "    except:\n",
    "        motifs_lst.append(f'NNNN,None,0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{motif_file_export_path}/{key}_motif_contributions.txt', 'w') as f:\n",
    "        f.write(';'.join(motifs_lst))\n",
    "print(';'.join(motifs_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
